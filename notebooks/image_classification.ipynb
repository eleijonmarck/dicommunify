{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage of Keras for image_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* configure random transformations and normalization operations to be done on your image data during training\n",
    "* instantiate generators of augmented image batches (and their labels) via .flow(data, labels) or .flow_from_directory(directory). These generators can then be used with the Keras model methods that accept data generators as inputs, fit_generator, evaluate_generator and predict_generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import regularizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "import numpy as np\n",
    "seed = 13\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU configuration, disregard if non-GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## use only 30 % of the memory\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports to display the svg image of the network\n",
    "from keras.utils import plot_model\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pydot\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, horizontal_flip=True, width_shift_range=0.1,\n",
    "                                  height_shift_range=0.1,zoom_range=0.1)\n",
    "\n",
    "# only rescaling augmentation for test samples\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dir = '../xraydata/processed/train'\n",
    "test_dir = '../xraydata/processed/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# this is a generaotr that will read pictures \n",
    "# found in sub folders of 'data/train',\n",
    "# and indefinitely generate batches of augmented image data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                train_dir,\n",
    "                target_size=(100,50),\n",
    "                shuffle=True,\n",
    "                color_mode='grayscale',\n",
    "                batch_size=batch_size,\n",
    "                class_mode='categorical') # since we use categoricalentropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# this is a similar generatr, for validation/test data\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(100,50),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inspirational architectures taken from \n",
    "[brain_segmentation](https://github.com/naldeborgh7575/brain_segmentation/blob/master/code/Segmentation_Models.py)\n",
    "[image_classification](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_train_samples = 400\n",
    "nb_test_samples = 100\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3,3), input_shape=(100,50,1), padding='same',\n",
    "                 kernel_regularizer=regularizers.l2(0.001),activity_regularizer=regularizers.l1(0.001)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(128, (3,3), padding='same'))#, kernel_regularizer=regularizers.l2(0.01),activity_regularizer=regularizers.l1(0.01)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "          \n",
    "adam = Adam(lr=0.0001)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-e151eba4e5df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mSVG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_to_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dot'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'svg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_11 (Conv2D)           (None, 100, 50, 64)       640       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 100, 50, 64)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 50, 25, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 50, 25, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 50, 25, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 50, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 25, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 25, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 38400)             0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 512)               19661312  \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 5)                 2565      \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 19,738,373\n",
      "Trainable params: 19,738,373\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name conv2d_11/kernel:0 is illegal; using conv2d_11/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_11/kernel:0 is illegal; using conv2d_11/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_11/bias:0 is illegal; using conv2d_11/bias_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_11/bias:0 is illegal; using conv2d_11/bias_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_12/kernel:0 is illegal; using conv2d_12/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_12/bias:0 is illegal; using conv2d_12/bias_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_12/bias:0 is illegal; using conv2d_12/bias_0 instead.\n",
      "INFO:tensorflow:Summary name dense_11/kernel:0 is illegal; using dense_11/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name dense_11/kernel:0 is illegal; using dense_11/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name dense_11/bias:0 is illegal; using dense_11/bias_0 instead.\n",
      "INFO:tensorflow:Summary name dense_11/bias:0 is illegal; using dense_11/bias_0 instead.\n",
      "INFO:tensorflow:Summary name dense_12/kernel:0 is illegal; using dense_12/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name dense_12/kernel:0 is illegal; using dense_12/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name dense_12/bias:0 is illegal; using dense_12/bias_0 instead.\n",
      "INFO:tensorflow:Summary name dense_12/bias:0 is illegal; using dense_12/bias_0 instead.\n",
      "Epoch 1/120\n",
      "12/12 [==============================] - 0s - loss: 491.4215 - acc: 0.2865 - val_loss: 475.1904 - val_acc: 0.2941\n",
      "Epoch 2/120\n",
      "12/12 [==============================] - 0s - loss: 437.4269 - acc: 0.4264 - val_loss: 432.8987 - val_acc: 0.4706\n",
      "Epoch 3/120\n",
      "12/12 [==============================] - 0s - loss: 400.1340 - acc: 0.4556 - val_loss: 435.3803 - val_acc: 0.5000\n",
      "Epoch 4/120\n",
      "12/12 [==============================] - 0s - loss: 367.7663 - acc: 0.5756 - val_loss: 387.1556 - val_acc: 0.4706\n",
      "Epoch 5/120\n",
      "12/12 [==============================] - 0s - loss: 342.8667 - acc: 0.5623 - val_loss: 354.0807 - val_acc: 0.5521\n",
      "Epoch 6/120\n",
      "12/12 [==============================] - 0s - loss: 306.8857 - acc: 0.5832 - val_loss: 350.8764 - val_acc: 0.5882\n",
      "Epoch 7/120\n",
      "12/12 [==============================] - 0s - loss: 288.0560 - acc: 0.6511 - val_loss: 296.4102 - val_acc: 0.5588\n",
      "Epoch 8/120\n",
      "12/12 [==============================] - 0s - loss: 265.9873 - acc: 0.6304 - val_loss: 272.5960 - val_acc: 0.5441\n",
      "Epoch 9/120\n",
      "12/12 [==============================] - 0s - loss: 244.2845 - acc: 0.5862 - val_loss: 238.3527 - val_acc: 0.5735\n",
      "Epoch 10/120\n",
      "12/12 [==============================] - 0s - loss: 222.4065 - acc: 0.6254 - val_loss: 216.8115 - val_acc: 0.6471\n",
      "Epoch 11/120\n",
      "12/12 [==============================] - 0s - loss: 205.7208 - acc: 0.6535 - val_loss: 213.8236 - val_acc: 0.6176\n",
      "Epoch 12/120\n",
      "12/12 [==============================] - 0s - loss: 192.0404 - acc: 0.6592 - val_loss: 184.2315 - val_acc: 0.6765\n",
      "Epoch 13/120\n",
      "12/12 [==============================] - 0s - loss: 180.7962 - acc: 0.6531 - val_loss: 190.7712 - val_acc: 0.6771\n",
      "Epoch 14/120\n",
      "12/12 [==============================] - 0s - loss: 172.4439 - acc: 0.6849 - val_loss: 165.9937 - val_acc: 0.6471\n",
      "Epoch 15/120\n",
      "12/12 [==============================] - 0s - loss: 156.8947 - acc: 0.6674 - val_loss: 155.6680 - val_acc: 0.6324\n",
      "Epoch 16/120\n",
      "12/12 [==============================] - 0s - loss: 146.1567 - acc: 0.6899 - val_loss: 148.6170 - val_acc: 0.7647\n",
      "Epoch 17/120\n",
      "12/12 [==============================] - 0s - loss: 134.7325 - acc: 0.6515 - val_loss: 136.7168 - val_acc: 0.6176\n",
      "Epoch 18/120\n",
      "12/12 [==============================] - 0s - loss: 130.1231 - acc: 0.7140 - val_loss: 131.5197 - val_acc: 0.7353\n",
      "Epoch 19/120\n",
      "12/12 [==============================] - 0s - loss: 118.3813 - acc: 0.6877 - val_loss: 127.5517 - val_acc: 0.6562\n",
      "Epoch 20/120\n",
      "12/12 [==============================] - 0s - loss: 110.6458 - acc: 0.6749 - val_loss: 119.7282 - val_acc: 0.6765\n",
      "Epoch 21/120\n",
      "12/12 [==============================] - 0s - loss: 102.4051 - acc: 0.6949 - val_loss: 111.4117 - val_acc: 0.6029\n",
      "Epoch 22/120\n",
      "12/12 [==============================] - 0s - loss: 101.7189 - acc: 0.6849 - val_loss: 103.8391 - val_acc: 0.6176\n",
      "Epoch 23/120\n",
      "12/12 [==============================] - 0s - loss: 93.6138 - acc: 0.7653 - val_loss: 95.8515 - val_acc: 0.6618\n",
      "Epoch 24/120\n",
      "12/12 [==============================] - 0s - loss: 90.0366 - acc: 0.7132 - val_loss: 92.0548 - val_acc: 0.6324\n",
      "Epoch 25/120\n",
      "12/12 [==============================] - 0s - loss: 86.3651 - acc: 0.6980 - val_loss: 86.4320 - val_acc: 0.6912\n",
      "Epoch 26/120\n",
      "12/12 [==============================] - 0s - loss: 82.6391 - acc: 0.7108 - val_loss: 85.4857 - val_acc: 0.6618\n",
      "Epoch 27/120\n",
      "12/12 [==============================] - 0s - loss: 82.9076 - acc: 0.7240 - val_loss: 82.8580 - val_acc: 0.6176\n",
      "Epoch 28/120\n",
      "12/12 [==============================] - 0s - loss: 76.7329 - acc: 0.7108 - val_loss: 82.5805 - val_acc: 0.6562\n",
      "Epoch 29/120\n",
      "12/12 [==============================] - 0s - loss: 73.6996 - acc: 0.7215 - val_loss: 77.2871 - val_acc: 0.6765\n",
      "Epoch 30/120\n",
      "12/12 [==============================] - 0s - loss: 71.1258 - acc: 0.7441 - val_loss: 75.8804 - val_acc: 0.7059\n",
      "Epoch 31/120\n",
      "12/12 [==============================] - 0s - loss: 68.2275 - acc: 0.7343 - val_loss: 72.0230 - val_acc: 0.6765\n",
      "Epoch 32/120\n",
      "12/12 [==============================] - 0s - loss: 67.4078 - acc: 0.7633 - val_loss: 73.8852 - val_acc: 0.7206\n",
      "Epoch 33/120\n",
      "12/12 [==============================] - 0s - loss: 65.9600 - acc: 0.7156 - val_loss: 68.2996 - val_acc: 0.6912\n",
      "Epoch 34/120\n",
      "12/12 [==============================] - 0s - loss: 62.8286 - acc: 0.7602 - val_loss: 70.2008 - val_acc: 0.6667\n",
      "Epoch 35/120\n",
      "12/12 [==============================] - 0s - loss: 60.9600 - acc: 0.7526 - val_loss: 62.4615 - val_acc: 0.7206\n",
      "Epoch 36/120\n",
      "12/12 [==============================] - 0s - loss: 60.6095 - acc: 0.6773 - val_loss: 62.2874 - val_acc: 0.7794\n",
      "Epoch 37/120\n",
      "12/12 [==============================] - 0s - loss: 57.4772 - acc: 0.7631 - val_loss: 58.9607 - val_acc: 0.6912\n",
      "Epoch 38/120\n",
      "12/12 [==============================] - 0s - loss: 57.5254 - acc: 0.7217 - val_loss: 60.8309 - val_acc: 0.7059\n",
      "Epoch 39/120\n",
      "12/12 [==============================] - 0s - loss: 55.4435 - acc: 0.7249 - val_loss: 57.7357 - val_acc: 0.7500\n",
      "Epoch 40/120\n",
      "12/12 [==============================] - 0s - loss: 56.5712 - acc: 0.7344 - val_loss: 56.2653 - val_acc: 0.7353\n",
      "Epoch 41/120\n",
      "12/12 [==============================] - 0s - loss: 53.5655 - acc: 0.7552 - val_loss: 55.1752 - val_acc: 0.7500.\n",
      "Epoch 42/120\n",
      "12/12 [==============================] - 0s - loss: 52.8441 - acc: 0.7840 - val_loss: 56.9455 - val_acc: 0.7353\n",
      "Epoch 43/120\n",
      "12/12 [==============================] - 0s - loss: 52.6299 - acc: 0.6799 - val_loss: 55.4712 - val_acc: 0.7647\n",
      "Epoch 44/120\n",
      "12/12 [==============================] - 0s - loss: 51.4527 - acc: 0.8071 - val_loss: 54.1465 - val_acc: 0.7206\n",
      "Epoch 45/120\n",
      "12/12 [==============================] - 0s - loss: 49.6777 - acc: 0.7500 - val_loss: 57.0325 - val_acc: 0.7941\n",
      "Epoch 46/120\n",
      "12/12 [==============================] - 0s - loss: 51.0764 - acc: 0.7162 - val_loss: 55.8695 - val_acc: 0.7353\n",
      "Epoch 47/120\n",
      "12/12 [==============================] - 0s - loss: 48.3578 - acc: 0.7996 - val_loss: 53.4612 - val_acc: 0.6618\n",
      "Epoch 48/120\n",
      "12/12 [==============================] - 0s - loss: 49.4906 - acc: 0.7838 - val_loss: 50.4557 - val_acc: 0.7794\n",
      "Epoch 49/120\n",
      "12/12 [==============================] - 0s - loss: 48.8274 - acc: 0.7235 - val_loss: 51.7021 - val_acc: 0.6765\n",
      "Epoch 50/120\n",
      "12/12 [==============================] - 0s - loss: 48.4724 - acc: 0.7524 - val_loss: 50.6136 - val_acc: 0.7206\n",
      "Epoch 51/120\n",
      "12/12 [==============================] - 0s - loss: 47.2226 - acc: 0.7892 - val_loss: 49.4886 - val_acc: 0.6471\n",
      "Epoch 52/120\n",
      "12/12 [==============================] - 0s - loss: 47.1429 - acc: 0.8071 - val_loss: 48.9430 - val_acc: 0.7353\n",
      "Epoch 53/120\n",
      "12/12 [==============================] - 0s - loss: 48.4830 - acc: 0.7734 - val_loss: 48.4712 - val_acc: 0.7794\n",
      "Epoch 54/120\n",
      "12/12 [==============================] - 0s - loss: 45.8787 - acc: 0.7866 - val_loss: 47.9180 - val_acc: 0.7059\n",
      "Epoch 55/120\n",
      "12/12 [==============================] - 0s - loss: 45.8738 - acc: 0.7478 - val_loss: 48.4888 - val_acc: 0.6765\n",
      "Epoch 56/120\n",
      "12/12 [==============================] - 0s - loss: 44.9524 - acc: 0.7763 - val_loss: 44.5886 - val_acc: 0.7059\n",
      "Epoch 57/120\n",
      "12/12 [==============================] - 0s - loss: 43.5651 - acc: 0.7940 - val_loss: 45.1079 - val_acc: 0.6765\n",
      "Epoch 58/120\n",
      "12/12 [==============================] - 0s - loss: 44.9681 - acc: 0.7785 - val_loss: 47.6512 - val_acc: 0.6912\n",
      "Epoch 59/120\n",
      "12/12 [==============================] - 0s - loss: 43.3103 - acc: 0.7966 - val_loss: 46.5024 - val_acc: 0.7353\n",
      "Epoch 60/120\n",
      "12/12 [==============================] - 0s - loss: 43.5564 - acc: 0.7626 - val_loss: 46.3827 - val_acc: 0.7353\n",
      "Epoch 61/120\n",
      "12/12 [==============================] - 0s - loss: 42.3657 - acc: 0.7787 - val_loss: 46.6385 - val_acc: 0.7353\n",
      "Epoch 62/120\n",
      "12/12 [==============================] - 0s - loss: 42.8920 - acc: 0.7657 - val_loss: 45.9975 - val_acc: 0.6912\n",
      "Epoch 63/120\n",
      "12/12 [==============================] - 0s - loss: 42.0173 - acc: 0.7811 - val_loss: 46.1088 - val_acc: 0.7206\n",
      "Epoch 64/120\n",
      "12/12 [==============================] - 0s - loss: 41.8535 - acc: 0.7948 - val_loss: 44.8758 - val_acc: 0.7059\n",
      "Epoch 65/120\n",
      "12/12 [==============================] - 0s - loss: 41.3032 - acc: 0.7735 - val_loss: 44.7330 - val_acc: 0.7206\n",
      "Epoch 66/120\n",
      "12/12 [==============================] - 0s - loss: 42.4740 - acc: 0.7917 - val_loss: 43.5693 - val_acc: 0.7941\n",
      "Epoch 67/120\n",
      "12/12 [==============================] - 0s - loss: 40.6251 - acc: 0.7838 - val_loss: 45.6485 - val_acc: 0.7500\n",
      "Epoch 68/120\n",
      "12/12 [==============================] - 0s - loss: 41.3141 - acc: 0.7733 - val_loss: 44.9440 - val_acc: 0.7059\n",
      "Epoch 69/120\n",
      "12/12 [==============================] - 0s - loss: 39.8760 - acc: 0.7890 - val_loss: 42.7829 - val_acc: 0.7941.79\n",
      "Epoch 70/120\n",
      "12/12 [==============================] - 0s - loss: 39.1480 - acc: 0.7994 - val_loss: 41.7708 - val_acc: 0.7941\n",
      "Epoch 71/120\n",
      "12/12 [==============================] - 0s - loss: 39.4287 - acc: 0.8177 - val_loss: 40.9833 - val_acc: 0.7353\n",
      "Epoch 72/120\n",
      "12/12 [==============================] - 0s - loss: 39.5670 - acc: 0.8251 - val_loss: 42.8696 - val_acc: 0.7647\n",
      "Epoch 73/120\n",
      "12/12 [==============================] - 0s - loss: 37.8373 - acc: 0.7733 - val_loss: 39.6186 - val_acc: 0.7206\n",
      "Epoch 74/120\n",
      "12/12 [==============================] - 0s - loss: 39.5884 - acc: 0.7659 - val_loss: 42.3470 - val_acc: 0.8088\n",
      "Epoch 75/120\n",
      "12/12 [==============================] - 0s - loss: 37.3820 - acc: 0.7866 - val_loss: 41.9726 - val_acc: 0.7941\n",
      "Epoch 76/120\n",
      "12/12 [==============================] - 0s - loss: 37.9307 - acc: 0.8256 - val_loss: 43.0321 - val_acc: 0.7292\n",
      "Epoch 77/120\n",
      "12/12 [==============================] - 0s - loss: 37.7151 - acc: 0.8354 - val_loss: 37.7733 - val_acc: 0.7794\n",
      "Epoch 78/120\n",
      "12/12 [==============================] - 0s - loss: 36.9523 - acc: 0.7990 - val_loss: 39.8876 - val_acc: 0.6912\n",
      "Epoch 79/120\n",
      "12/12 [==============================] - 0s - loss: 38.0576 - acc: 0.8099 - val_loss: 37.9246 - val_acc: 0.7794\n",
      "Epoch 80/120\n",
      "12/12 [==============================] - 0s - loss: 36.0462 - acc: 0.8073 - val_loss: 39.1511 - val_acc: 0.7941\n",
      "Epoch 81/120\n",
      "12/12 [==============================] - 0s - loss: 36.8657 - acc: 0.8356 - val_loss: 37.2912 - val_acc: 0.7500\n",
      "Epoch 82/120\n",
      "12/12 [==============================] - 0s - loss: 35.1736 - acc: 0.8384 - val_loss: 40.2614 - val_acc: 0.7794\n",
      "Epoch 83/120\n",
      "12/12 [==============================] - 0s - loss: 36.0458 - acc: 0.8095 - val_loss: 37.5680 - val_acc: 0.7941\n",
      "Epoch 84/120\n",
      "12/12 [==============================] - 0s - loss: 35.3603 - acc: 0.8151 - val_loss: 36.8824 - val_acc: 0.7794\n",
      "Epoch 85/120\n",
      "12/12 [==============================] - 0s - loss: 35.3100 - acc: 0.8151 - val_loss: 38.4622 - val_acc: 0.7353\n",
      "Epoch 86/120\n",
      "12/12 [==============================] - 0s - loss: 34.3861 - acc: 0.8049 - val_loss: 37.8570 - val_acc: 0.7647\n",
      "Epoch 87/120\n",
      "12/12 [==============================] - 0s - loss: 34.4806 - acc: 0.8175 - val_loss: 36.2219 - val_acc: 0.7941\n",
      "Epoch 88/120\n",
      "12/12 [==============================] - 0s - loss: 33.4653 - acc: 0.8386 - val_loss: 34.5320 - val_acc: 0.7941\n",
      "Epoch 89/120\n",
      "12/12 [==============================] - 0s - loss: 34.1441 - acc: 0.8258 - val_loss: 36.3254 - val_acc: 0.7353\n",
      "Epoch 90/120\n",
      "12/12 [==============================] - 0s - loss: 32.7950 - acc: 0.8254 - val_loss: 35.1167 - val_acc: 0.7647\n",
      "Epoch 91/120\n",
      "12/12 [==============================] - 0s - loss: 33.4930 - acc: 0.7990 - val_loss: 36.5274 - val_acc: 0.8382\n",
      "Epoch 92/120\n",
      "12/12 [==============================] - 0s - loss: 34.0332 - acc: 0.8359 - val_loss: 32.9920 - val_acc: 0.8088\n",
      "Epoch 93/120\n",
      "12/12 [==============================] - 0s - loss: 33.0143 - acc: 0.8101 - val_loss: 36.7189 - val_acc: 0.7353\n",
      "Epoch 94/120\n",
      "12/12 [==============================] - 0s - loss: 31.4202 - acc: 0.8543 - val_loss: 34.8164 - val_acc: 0.7353\n",
      "Epoch 95/120\n",
      "12/12 [==============================] - 0s - loss: 32.4624 - acc: 0.8205 - val_loss: 34.3347 - val_acc: 0.8088\n",
      "Epoch 96/120\n",
      "12/12 [==============================] - 0s - loss: 31.4140 - acc: 0.8676 - val_loss: 33.6114 - val_acc: 0.7794\n",
      "Epoch 97/120\n",
      "12/12 [==============================] - 0s - loss: 32.1646 - acc: 0.8412 - val_loss: 34.7846 - val_acc: 0.7647\n",
      "Epoch 98/120\n",
      "12/12 [==============================] - 0s - loss: 30.5419 - acc: 0.8465 - val_loss: 33.0154 - val_acc: 0.8088\n",
      "Epoch 99/120\n",
      "12/12 [==============================] - 0s - loss: 31.0862 - acc: 0.8511 - val_loss: 33.3810 - val_acc: 0.7941\n",
      "Epoch 100/120\n",
      "12/12 [==============================] - 0s - loss: 30.6015 - acc: 0.8410 - val_loss: 35.1822 - val_acc: 0.7812\n",
      "Epoch 101/120\n",
      "12/12 [==============================] - 0s - loss: 30.6578 - acc: 0.8720 - val_loss: 34.0769 - val_acc: 0.7794\n",
      "Epoch 102/120\n",
      "12/12 [==============================] - 0s - loss: 30.0468 - acc: 0.8308 - val_loss: 34.6599 - val_acc: 0.7647\n",
      "Epoch 103/120\n",
      "12/12 [==============================] - 0s - loss: 29.7244 - acc: 0.8441 - val_loss: 32.7560 - val_acc: 0.7647\n",
      "Epoch 104/120\n",
      "12/12 [==============================] - 0s - loss: 29.7172 - acc: 0.8175 - val_loss: 32.2187 - val_acc: 0.7794\n",
      "Epoch 105/120\n",
      "12/12 [==============================] - 0s - loss: 30.4482 - acc: 0.8464 - val_loss: 33.0702 - val_acc: 0.7500\n",
      "Epoch 106/120\n",
      "12/12 [==============================] - 0s - loss: 29.0414 - acc: 0.8441 - val_loss: 30.8858 - val_acc: 0.7941\n",
      "Epoch 107/120\n",
      "12/12 [==============================] - 0s - loss: 28.4494 - acc: 0.8340 - val_loss: 32.3679 - val_acc: 0.7794\n",
      "Epoch 108/120\n",
      "12/12 [==============================] - 0s - loss: 29.2058 - acc: 0.8432 - val_loss: 30.6262 - val_acc: 0.7941\n",
      "Epoch 109/120\n",
      "12/12 [==============================] - 0s - loss: 28.2766 - acc: 0.8539 - val_loss: 30.8166 - val_acc: 0.8088\n",
      "Epoch 110/120\n",
      "12/12 [==============================] - 0s - loss: 27.6925 - acc: 0.8641 - val_loss: 28.6368 - val_acc: 0.7794\n",
      "Epoch 111/120\n",
      "12/12 [==============================] - 0s - loss: 28.3321 - acc: 0.8306 - val_loss: 29.8873 - val_acc: 0.7206\n",
      "Epoch 112/120\n",
      "12/12 [==============================] - 0s - loss: 27.1450 - acc: 0.8388 - val_loss: 31.3318 - val_acc: 0.7647\n",
      "Epoch 113/120\n",
      "12/12 [==============================] - 0s - loss: 27.9004 - acc: 0.8334 - val_loss: 28.1684 - val_acc: 0.7647\n",
      "Epoch 114/120\n",
      "12/12 [==============================] - 0s - loss: 27.2860 - acc: 0.8278 - val_loss: 28.2346 - val_acc: 0.7941\n",
      "Epoch 115/120\n",
      "12/12 [==============================] - 0s - loss: 26.2494 - acc: 0.8487 - val_loss: 29.7194 - val_acc: 0.8235\n",
      "Epoch 116/120\n",
      "12/12 [==============================] - 0s - loss: 27.0083 - acc: 0.8539 - val_loss: 28.8189 - val_acc: 0.7059\n",
      "Epoch 117/120\n",
      "12/12 [==============================] - 0s - loss: 26.4076 - acc: 0.8541 - val_loss: 29.5266 - val_acc: 0.8088\n",
      "Epoch 118/120\n",
      "12/12 [==============================] - 0s - loss: 27.2981 - acc: 0.8490 - val_loss: 27.8775 - val_acc: 0.8088\n",
      "Epoch 119/120\n",
      "12/12 [==============================] - 0s - loss: 26.1768 - acc: 0.8565 - val_loss: 27.6374 - val_acc: 0.7500\n",
      "Epoch 120/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s - loss: 25.7919 - acc: 0.8282 - val_loss: 29.2026 - val_acc: 0.8088\n"
     ]
    }
   ],
   "source": [
    "run_count += 1\n",
    "from keras.callbacks import TensorBoard\n",
    "tbCallBack = TensorBoard(log_dir=\"./summary/run_{}\".format(run_count), \n",
    "                         histogram_freq=2, write_graph=True, \n",
    "                         write_images=True)\n",
    "\n",
    "model.fit_generator(train_generator,\n",
    "                   steps_per_epoch=nb_train_samples // batch_size,\n",
    "                   epochs=120,\n",
    "                   validation_data=test_generator,\n",
    "                   validation_steps=nb_test_samples // batch_size,\n",
    "                   callbacks=[tbCallBack])\n",
    "\n",
    "model.save_weights('first_try.h5')\n",
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  9.55800056e-01,   9.19995946e-04,   7.95655724e-05,\n",
       "          2.66963220e-03,   4.05308120e-02]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.misc\n",
    "image = scipy.misc.imread('../xraydata/blackandwhitecar.jpeg', mode='L')\n",
    "#image = scipy.misc.imread('../xraydata/x_ray_heart_by_mmattes.jpg', mode='L')\n",
    "#image = scipy.misc.imread('../xraydata/processed/test/Body/Body_47524821.jpeg',mode='L')\n",
    "image = scipy.misc.imresize(image, (100,50))\n",
    "image = image / 255\n",
    "image = np.expand_dims(image, axis=2)\n",
    "\n",
    "model.save('80_mf.h5')\n",
    "image = image.reshape((1,) + image.shape)\n",
    "model.predict_proba(image, verbose=1, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Body': 0,\n",
       " 'Head-Neck': 1,\n",
       " 'Lower-Limb': 2,\n",
       " 'True-Negative': 3,\n",
       " 'Upper-Limb': 4}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 50)\n",
      "(100, 50, 1)\n",
      "(100, 50, 3)\n"
     ]
    }
   ],
   "source": [
    "image = scipy.misc.imread('../xraydata/processed/test/Lower-Limb/Lower-Limb_85026021.jpeg',mode='L')\n",
    "print(image.shape)\n",
    "image = np.expand_dims(image, axis=2)\n",
    "print(image.shape)\n",
    "image = np.tile(image, (1, 3)) \n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
